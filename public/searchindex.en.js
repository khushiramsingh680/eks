var relearn_searchindex = [
  {
    "breadcrumb": "",
    "content": "Cluster Setup and Configuration Create AWS EKS Cluster using eksctl CLI Install and configure eksctl. Create an EKS cluster with worker nodes. Set up kubectl to manage the cluster. Verify the cluster resources and configuration. Fundamentals Docker Fundamentals Understand containers vs. virtual machines. Learn essential Docker commands for container lifecycle management. Build, tag, and push Docker images. Work with Docker registries, such as AWS ECR. Kubernetes Fundamentals Pods: Core Kubernetes objects and their lifecycle. ReplicaSets: Manage pod replication and high availability. Deployments: Rollouts, updates, and rollbacks. Services: NodePort Service. ClusterIP Service. LoadBalancer Service. ExternalName Service. EKS Storage Solutions EKS Storage with AWS EBS CSI Driver Install and configure the AWS EBS CSI Driver. Create Persistent Volumes (PV) and Persistent Volume Claims (PVC). Mount EBS volumes to Kubernetes pods. EKS Storage with AWS RDS MySQL Database Integrate an RDS MySQL database with Kubernetes workloads. Use Kubernetes Secrets to store database credentials securely. Kubernetes Important Concepts for Application Deployments Kubernetes - Secrets Securely manage sensitive data like passwords and API keys. Create, update, and mount secrets in pods. Kubernetes - Init Containers Configure Init Containers to run setup tasks before the main container starts. Kubernetes - Liveness \u0026 Readiness Probes Implement health checks for application containers. Configure probes to restart unhealthy containers or delay traffic to unready pods. Kubernetes - Requests \u0026 Limits Manage resource requests and limits to optimize workload performance. Kubernetes - Namespaces, LimitRange, and Resource Quota Use namespaces to organize resources. Set up LimitRange and ResourceQuota for better resource control. Load Balancing Solutions Load Balancing using CLB - AWS Classic Load Balancer Expose Kubernetes services with AWS Classic Load Balancer. Load Balancing using NLB - AWS Network Load Balancer Configure AWS NLB for high-performance load balancing. Load Balancing using ALB - AWS Application Load Balancer ALB Ingress Controller - Install: Set up ALB Ingress Controller for Kubernetes. ALB Ingress - Basics: Basic configurations for ALB ingress. ALB Ingress - Context Path-based Routing: Route requests based on paths. ALB Ingress - SSL: Enable SSL with AWS Certificate Manager. ALB Ingress - SSL Redirect (HTTP to HTTPS): Enforce HTTPS traffic. ALB Ingress - External DNS: Integrate with Route53 for DNS management. Serverless Deployments Deploy Kubernetes Workloads on AWS Fargate Deploy applications on AWS Fargate for serverless computing. Configure Fargate Profiles: Basic profiles. Advanced profiles using YAML. CI/CD and Monitoring Build and Push Containers to AWS ECR Build Docker images and push them to AWS ECR. Deploy ECR-based images to EKS. DevOps with AWS Developer Tools Use CodeCommit, CodeBuild, and CodePipeline for CI/CD pipelines. Microservices Deployment on EKS Service Discovery: Enable service discovery in Kubernetes. Distributed Tracing with AWS X-Ray: Track requests in microservices. Canary Deployments: Gradually roll out updates to reduce risk. EKS Monitoring using CloudWatch Set up CloudWatch Agent and Fluentd for Container Insights. Monitor logs, metrics, and alarms using CloudWatch. Kubernetes Scaling EKS HPA - Horizontal Pod Autoscaler Configure HPA to scale pods based on resource metrics. EKS VPA - Vertical Pod Autoscaler Automatically adjust pod resource requests and limits. EKS CA - Cluster Autoscaler Scale worker nodes based on demand. AWS Services Covered AWS EKS: Elastic Kubernetes Service. AWS EBS: Elastic Block Store. AWS RDS: Relational Database Service (MySQL). AWS CLB: Classic Load Balancer. AWS NLB: Network Load Balancer. AWS ALB: Application Load Balancer. AWS Fargate: Serverless computing for Kubernetes. AWS ECR: Elastic Container Registry. AWS Developer Tools: CodeCommit, CodeBuild, CodePipeline. AWS X-Ray: Distributed tracing for microservices. AWS CloudWatch: Container Insights, Log Groups, Log Insights, and Alarms. AWS Route53: DNS management. AWS Certificate Manager: SSL/TLS certificates. AWS SNS: Simple Notification Service. Kubernetes Concepts Covered Kubernetes Architecture Understand the core components of Kubernetes. Core Objects Pods: Manage containerized applications. ReplicaSets: Ensure pod availability. Deployments: Manage application updates. Services: NodePort, ClusterIP, ExternalName, and LoadBalancer services. Kubernetes Networking Ingress Services: SSL configuration and redirection. Integration with external DNS. Resource Management Requests \u0026 Limits: Optimize workload performance. Namespaces: Create namespaces imperatively. Configure LimitRange and ResourceQuota. Storage Storage Classes: Automate PV provisioning. Persistent Volumes (PV): Manage storage resources. Persistent Volume Claims (PVC): Request storage dynamically. Advanced Concepts Secrets: Manage sensitive information securely. Init Containers: Pre-start initialization tasks. Liveness \u0026 Readiness Probes: Ensure application health. Annotations: Add metadata to Kubernetes objects. Scaling and Autoscaling HPA - Horizontal Pod Autoscaler: Scale pods based on metrics. VPA - Vertical Pod Autoscaler: Adjust resource allocation dynamically. CA - Cluster Autoscaler: Scale nodes automatically. Logging and Monitoring DaemonSets: Fluentd DaemonSet for centralized logging. ConfigMaps: Manage application configuration data. Deployment Strategies Canary Deployments: Gradual updates for testing and stability.",
    "description": "Cluster Setup and Configuration Create AWS EKS Cluster using eksctl CLI Install and configure eksctl. Create an EKS cluster with worker nodes. Set up kubectl to manage the cluster. Verify the cluster resources and configuration. Fundamentals Docker Fundamentals Understand containers vs. virtual machines. Learn essential Docker commands for container lifecycle management. Build, tag, and push Docker images. Work with Docker registries, such as AWS ECR. Kubernetes Fundamentals Pods: Core Kubernetes objects and their lifecycle. ReplicaSets: Manage pod replication and high availability. Deployments: Rollouts, updates, and rollbacks. Services: NodePort Service. ClusterIP Service. LoadBalancer Service. ExternalName Service. EKS Storage Solutions EKS Storage with AWS EBS CSI Driver Install and configure the AWS EBS CSI Driver. Create Persistent Volumes (PV) and Persistent Volume Claims (PVC). Mount EBS volumes to Kubernetes pods. EKS Storage with AWS RDS MySQL Database Integrate an RDS MySQL database with Kubernetes workloads. Use Kubernetes Secrets to store database credentials securely. Kubernetes Important Concepts for Application Deployments Kubernetes - Secrets Securely manage sensitive data like passwords and API keys. Create, update, and mount secrets in pods. Kubernetes - Init Containers Configure Init Containers to run setup tasks before the main container starts. Kubernetes - Liveness \u0026 Readiness Probes Implement health checks for application containers. Configure probes to restart unhealthy containers or delay traffic to unready pods. Kubernetes - Requests \u0026 Limits Manage resource requests and limits to optimize workload performance. Kubernetes - Namespaces, LimitRange, and Resource Quota Use namespaces to organize resources. Set up LimitRange and ResourceQuota for better resource control. Load Balancing Solutions Load Balancing using CLB - AWS Classic Load Balancer Expose Kubernetes services with AWS Classic Load Balancer. Load Balancing using NLB - AWS Network Load Balancer Configure AWS NLB for high-performance load balancing. Load Balancing using ALB - AWS Application Load Balancer ALB Ingress Controller - Install: Set up ALB Ingress Controller for Kubernetes. ALB Ingress - Basics: Basic configurations for ALB ingress. ALB Ingress - Context Path-based Routing: Route requests based on paths. ALB Ingress - SSL: Enable SSL with AWS Certificate Manager. ALB Ingress - SSL Redirect (HTTP to HTTPS): Enforce HTTPS traffic. ALB Ingress - External DNS: Integrate with Route53 for DNS management. Serverless Deployments Deploy Kubernetes Workloads on AWS Fargate Deploy applications on AWS Fargate for serverless computing. Configure Fargate Profiles: Basic profiles. Advanced profiles using YAML. CI/CD and Monitoring Build and Push Containers to AWS ECR Build Docker images and push them to AWS ECR. Deploy ECR-based images to EKS. DevOps with AWS Developer Tools Use CodeCommit, CodeBuild, and CodePipeline for CI/CD pipelines. Microservices Deployment on EKS Service Discovery: Enable service discovery in Kubernetes. Distributed Tracing with AWS X-Ray: Track requests in microservices. Canary Deployments: Gradually roll out updates to reduce risk. EKS Monitoring using CloudWatch Set up CloudWatch Agent and Fluentd for Container Insights. Monitor logs, metrics, and alarms using CloudWatch. Kubernetes Scaling EKS HPA - Horizontal Pod Autoscaler Configure HPA to scale pods based on resource metrics. EKS VPA - Vertical Pod Autoscaler Automatically adjust pod resource requests and limits. EKS CA - Cluster Autoscaler Scale worker nodes based on demand. AWS Services Covered AWS EKS: Elastic Kubernetes Service. AWS EBS: Elastic Block Store. AWS RDS: Relational Database Service (MySQL). AWS CLB: Classic Load Balancer. AWS NLB: Network Load Balancer. AWS ALB: Application Load Balancer. AWS Fargate: Serverless computing for Kubernetes. AWS ECR: Elastic Container Registry. AWS Developer Tools: CodeCommit, CodeBuild, CodePipeline. AWS X-Ray: Distributed tracing for microservices. AWS CloudWatch: Container Insights, Log Groups, Log Insights, and Alarms. AWS Route53: DNS management. AWS Certificate Manager: SSL/TLS certificates. AWS SNS: Simple Notification Service. Kubernetes Concepts Covered Kubernetes Architecture Understand the core components of Kubernetes. Core Objects Pods: Manage containerized applications. ReplicaSets: Ensure pod availability. Deployments: Manage application updates. Services: NodePort, ClusterIP, ExternalName, and LoadBalancer services. Kubernetes Networking Ingress Services: SSL configuration and redirection. Integration with external DNS. Resource Management Requests \u0026 Limits: Optimize workload performance. Namespaces: Create namespaces imperatively. Configure LimitRange and ResourceQuota. Storage Storage Classes: Automate PV provisioning. Persistent Volumes (PV): Manage storage resources. Persistent Volume Claims (PVC): Request storage dynamically. Advanced Concepts Secrets: Manage sensitive information securely. Init Containers: Pre-start initialization tasks. Liveness \u0026 Readiness Probes: Ensure application health. Annotations: Add metadata to Kubernetes objects. Scaling and Autoscaling HPA - Horizontal Pod Autoscaler: Scale pods based on metrics. VPA - Vertical Pod Autoscaler: Adjust resource allocation dynamically. CA - Cluster Autoscaler: Scale nodes automatically. Logging and Monitoring DaemonSets: Fluentd DaemonSet for centralized logging. ConfigMaps: Manage application configuration data. Deployment Strategies Canary Deployments: Gradual updates for testing and stability.",
    "tags": [],
    "title": "Elastic Kubernetes Service (EKS)",
    "uri": "/eks/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "Elastic Kubernetes Service (EKS)",
    "content": "EKS - Create Cluster List of Topics Install CLIs AWS CLI kubectl eksctl Create EKS Cluster Create EKS Node Groups Understand EKS Cluster Pricing EKS Control Plane EKS Worker Nodes EKS Fargate Profile Delete EKS Clusters Install AWS, kubectl \u0026 eksctl CLI’s Step-00: Introduction Install AWS CLI Install kubectl CLI Install eksctl CLI Step-01: Install AWS CLI Reference-1: https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html Reference-2: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html Step-01-01: MAC - Install and configure AWS CLI Download the binary and install via command line using below two commands. # Download Binary\rcurl \"https://awscli.amazonaws.com/AWSCLIV2.pkg\" -o \"AWSCLIV2.pkg\"\r# Install the binary\rsudo installer -pkg ./AWSCLIV2.pkg -target /\rVerify the installation aws --version\raws-cli/2.0.7 Python/3.7.4 Darwin/19.4.0 botocore/2.0.0dev11\rwhich aws\rReference: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html Step-01-02: Windows 10 - Install and configure AWS CLI The AWS CLI version 2 is supported on Windows XP or later. The AWS CLI version 2 supports only 64-bit versions of Windows. Download Binary: https://awscli.amazonaws.com/AWSCLIV2.msi Install the downloaded binary (standard windows install) aws --version\raws-cli/2.0.8 Python/3.7.5 Windows/10 botocore/2.0.0dev12\rReference: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-windows.html Step-01-03: Configure AWS Command Line using Security Credentials Go to AWS Management Console –\u003e Services –\u003e IAM Select the IAM User: kalyan Important Note: Use only IAM user to generate Security Credentials. Never ever use Root User. (Highly not recommended) Click on Security credentials tab Click on Create access key Copy Access ID and Secret access key Go to command line and provide the required details aws configure\rAWS Access Key ID [None]: ABCDEFGHIAZBERTUCNGG (Replace your creds when prompted)\rAWS Secret Access Key [None]: uMe7fumK1IdDB094q2sGFhM5Bqt3HQRw3IHZzBDTm (Replace your creds when prompted)\rDefault region name [None]: us-east-1\rDefault output format [None]: json\rTest if AWS CLI is working after configuring the above aws ec2 describe-vpcs\rStep-02: Install kubectl CLI IMPORTANT NOTE: Kubectl binaries for EKS please prefer to use from Amazon (Amazon EKS-vended kubectl binary) This will help us to get the exact Kubectl client version based on our EKS Cluster version. You can use the below documentation link to download the binary. Reference: https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html Step-02-01: MAC - Install and configure kubectl Kubectl version we are using here is 1.16.8 (It may vary based on Cluster version you are planning use in AWS EKS) # Download the Package\rmkdir kubectlbinary\rcd kubectlbinary\rcurl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.16.8/2020-04-16/bin/darwin/amd64/kubectl\r# Provide execute permissions\rchmod +x ./kubectl\r# Set the Path by copying to user Home Directory\rmkdir -p $HOME/bin \u0026\u0026 cp ./kubectl $HOME/bin/kubectl \u0026\u0026 export PATH=$PATH:$HOME/bin\recho 'export PATH=$PATH:$HOME/bin' \u003e\u003e ~/.bash_profile\r# Verify the kubectl version\rkubectl version --short --client\rOutput: Client Version: v1.16.8-eks-e16311\rStep-02-02: Windows 10 - Install and configure kubectl Install kubectl on Windows 10 mkdir kubectlbinary\rcd kubectlbinary\rcurl -o kubectl.exe https://amazon-eks.s3.us-west-2.amazonaws.com/1.16.8/2020-04-16/bin/windows/amd64/kubectl.exe\rUpdate the system Path environment variable C:\\Users\\KALYAN\\Documents\\kubectlbinary\rVerify the kubectl client version kubectl version --short --client\rkubectl version --client\rStep-03: Install eksctl CLI Step-03-01: eksctl on Mac # Install Homebrew on MacOs\r/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\r# Install the Weaveworks Homebrew tap.\rbrew tap weaveworks/tap\r# Install the Weaveworks Homebrew tap.\rbrew install weaveworks/tap/eksctl\r# Verify eksctl version\reksctl version\rStep-03-02: eksctl on windows or linux For windows and linux OS, you can refer below documentation link. Reference: https://docs.aws.amazon.com/eks/latest/userguide/eksctl.html#installing-eksctl References: https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html Create EKS Cluster \u0026 Node Groups Step-00: Introduction Understand about EKS Core Objects Control Plane Worker Nodes \u0026 Node Groups Fargate Profiles VPC Create EKS Cluster Associate EKS Cluster to IAM OIDC Provider Create EKS Node Groups Verify Cluster, Node Groups, EC2 Instances, IAM Policies and Node Groups Step-01: Create EKS Cluster using eksctl It will take 15 to 20 minutes to create the Cluster Control Plane # Create Cluster\reksctl create cluster --name=eksdemo1 \\\r--region=us-east-1 \\\r--zones=us-east-1a,us-east-1b \\\r--without-nodegroup # Get List of clusters\reksctl get cluster Step-02: Create \u0026 Associate IAM OIDC Provider for our EKS Cluster To enable and use AWS IAM roles for Kubernetes service accounts on our EKS cluster, we must create \u0026 associate OIDC identity provider. To do so using eksctl we can use the below command. Use latest eksctl version (as on today the latest version is 0.21.0) # Template\reksctl utils associate-iam-oidc-provider \\\r--region region-code \\\r--cluster \u003ccluter-name\u003e \\\r--approve\r# Replace with region \u0026 cluster name\reksctl utils associate-iam-oidc-provider \\\r--region us-east-1 \\\r--cluster eksdemo1 \\\r--approve\rStep-03: Create EC2 Keypair Create a new EC2 Keypair with name as kube-demo This keypair we will use it when creating the EKS NodeGroup. This will help us to login to the EKS Worker Nodes using Terminal. Step-04: Create Node Group with additional Add-Ons in Public Subnets These add-ons will create the respective IAM policies for us automatically within our Node Group role. # Create Public Node Group eksctl create nodegroup --cluster=eksdemo1 \\\r--region=us-east-1 \\\r--name=eksdemo1-ng-public1 \\\r--node-type=t3.medium \\\r--nodes=2 \\\r--nodes-min=2 \\\r--nodes-max=4 \\\r--node-volume-size=20 \\\r--ssh-access \\\r--ssh-public-key=kube-demo \\\r--managed \\\r--asg-access \\\r--external-dns-access \\\r--full-ecr-access \\\r--appmesh-access \\\r--alb-ingress-access Step-05: Verify Cluster \u0026 Nodes Verify NodeGroup subnets to confirm EC2 Instances are in Public Subnet Verify the node group subnet to ensure it created in public subnets Go to Services -\u003e EKS -\u003e eksdemo -\u003e eksdemo1-ng1-public Click on Associated subnet in Details tab Click on Route Table Tab. We should see that internet route via Internet Gateway (0.0.0.0/0 -\u003e igw-xxxxxxxx) Verify Cluster, NodeGroup in EKS Management Console Go to Services -\u003e Elastic Kubernetes Service -\u003e eksdemo1 List Worker Nodes # List EKS clusters\reksctl get cluster\r# List NodeGroups in a cluster\reksctl get nodegroup --cluster=\u003cclusterName\u003e\r# List Nodes in current kubernetes cluster\rkubectl get nodes -o wide\r# Our kubectl context should be automatically changed to new cluster\rkubectl config view --minify\rVerify Worker Node IAM Role and list of Policies Go to Services -\u003e EC2 -\u003e Worker Nodes Click on IAM Role associated to EC2 Worker Nodes Verify Security Group Associated to Worker Nodes Go to Services -\u003e EC2 -\u003e Worker Nodes Click on Security Group associated to EC2 Instance which contains remote in the name. Verify CloudFormation Stacks Verify Control Plane Stack \u0026 Events Verify NodeGroup Stack \u0026 Events Login to Worker Node using Keypai kube-demo Login to worker node # For MAC or Linux or Windows10\rssh -i kube-demo.pem ec2-user@\u003cPublic-IP-of-Worker-Node\u003e\r# For Windows 7\rUse putty\rStep-06: Update Worker Nodes Security Group to allow all traffic We need to allow All Traffic on worker node security group Additional References https://docs.aws.amazon.com/eks/latest/userguide/enable-iam-roles-for-service-accounts.html https://docs.aws.amazon.com/eks/latest/userguide/create-service-account-iam-policy-and-role.html EKS Cluster Pricing Steo-01: Very Important EKS Pricing Note EKS is not free (Unlike other AWS Services) In short, no free-tier for EKS. EKS Cluster Pricing - We pay $0.10 per hour for each Amazon EKS cluster\r- Per Day: $2.4\r- For 30 days: $72\rEKS Worker Nodes Pricing - EC2 - You pay for AWS resources (e.g. EC2 instances or EBS volumes) - T3 Medium Server in N.Virginia\r- $0.0416 per Hour\r- Per Day: $0.9984 - Approximately $1\r- Per Month: $30 per 1 t3.medium server\r- Reference: https://aws.amazon.com/ec2/pricing/on-demand/\r- In short, if we run 1 EKS Cluster and 1 t3.medium worker node **continuously** for 1 month, our bill is going to be around $102 to $110\r- If we take 5 days to complete this course, and if we run 1 EKS Cluster and 2 t3.medium Worker nodes continuosly for 5 days it will cost us approximately around $25. EKS Fargate Profile - AWS Fargate pricing is calculated based on the **vCPU and memory** resources used from the time you start to download your container image until the EKS Pod terminates.\r- **Reference:** https://aws.amazon.com/fargate/pricing/ - Amazon EKS support for AWS Fargate is available in us-east-1, us-east-2, eu-west-1, and ap-northeast-1.\rImportant Notes Important Note-1: If you are using your personal AWS Account, then ensure you delete and recreate cluster and worker nodes as and when needed. Important Note-2: We cant stop our EC2 Instances which are in Kubernetes cluster unlike regular EC2 Instances. So we need to delete the worker nodes (Node Group) if we are not using it during our learning process. Delete EKS Cluster \u0026 Node Groups Step-01: Delete Node Group We can delete a nodegroup separately using below eksctl delete nodegroup # List EKS Clusters\reksctl get clusters\r# Capture Node Group name\reksctl get nodegroup --cluster=\u003cclusterName\u003e\reksctl get nodegroup --cluster=eksdemo1\r# Delete Node Group\reksctl delete nodegroup --cluster=\u003cclusterName\u003e --name=\u003cnodegroupName\u003e\reksctl delete nodegroup --cluster=eksdemo1 --name=eksdemo1-ng-public1\rStep-02: Delete Cluster We can delete cluster using eksctl delete cluster # Delete Cluster\reksctl delete cluster \u003cclusterName\u003e\reksctl delete cluster eksdemo1\rImportant Notes Note-1: Rollback any Security Group Changes When we create a EKS cluster using eksctl it creates the worker node security group with only port 22 access. When we progress through the course, we will be creating many NodePort Services to access and test our applications via browser. During this process, we need to add an additional rule to this automatically created security group, allowing access to our applications we have deployed. So the point we need to understand here is when we are deleting the cluster using eksctl, its core components should be in same state which means roll back the change we have done to security group before deleting the cluster. In this way, cluster will get deleted without any issues, else we might have issues and we need to refer cloudformation events and manually delete few things. In short, we need to go to many places for deletions. Note-2: Rollback any EC2 Worker Node Instance Role - Policy changes When we are doing EBS Storage Section with EBS CSI Driver we will add a custom policy to worker node IAM role. When you are deleting the cluster, first roll back that change and delete it. This way we don’t face any issues during cluster deletion.",
    "description": "EKS - Create Cluster List of Topics Install CLIs AWS CLI kubectl eksctl Create EKS Cluster Create EKS Node Groups Understand EKS Cluster Pricing EKS Control Plane EKS Worker Nodes EKS Fargate Profile Delete EKS Clusters Install AWS, kubectl \u0026 eksctl CLI’s Step-00: Introduction Install AWS CLI Install kubectl CLI Install eksctl CLI Step-01: Install AWS CLI Reference-1: https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html Reference-2: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html Step-01-01: MAC - Install and configure AWS CLI Download the binary and install via command line using below two commands. # Download Binary\rcurl \"https://awscli.amazonaws.com/AWSCLIV2.pkg\" -o \"AWSCLIV2.pkg\"\r# Install the binary\rsudo installer -pkg ./AWSCLIV2.pkg -target /\rVerify the installation aws --version\raws-cli/2.0.7 Python/3.7.4 Darwin/19.4.0 botocore/2.0.0dev11\rwhich aws\rReference: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html Step-01-02: Windows 10 - Install and configure AWS CLI The AWS CLI version 2 is supported on Windows XP or later. The AWS CLI version 2 supports only 64-bit versions of Windows. Download Binary: https://awscli.amazonaws.com/AWSCLIV2.msi Install the downloaded binary (standard windows install) aws --version\raws-cli/2.0.8 Python/3.7.5 Windows/10 botocore/2.0.0dev12\rReference: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-windows.html Step-01-03: Configure AWS Command Line using Security Credentials Go to AWS Management Console –\u003e Services –\u003e IAM Select the IAM User: kalyan Important Note: Use only IAM user to generate Security Credentials. Never ever use Root User. (Highly not recommended) Click on Security credentials tab Click on Create access key Copy Access ID and Secret access key Go to command line and provide the required details aws configure\rAWS Access Key ID [None]: ABCDEFGHIAZBERTUCNGG (Replace your creds when prompted)\rAWS Secret Access Key [None]: uMe7fumK1IdDB094q2sGFhM5Bqt3HQRw3IHZzBDTm (Replace your creds when prompted)\rDefault region name [None]: us-east-1\rDefault output format [None]: json\rTest if AWS CLI is working after configuring the above aws ec2 describe-vpcs\rStep-02: Install kubectl CLI IMPORTANT NOTE: Kubectl binaries for EKS please prefer to use from Amazon (Amazon EKS-vended kubectl binary) This will help us to get the exact Kubectl client version based on our EKS Cluster version. You can use the below documentation link to download the binary. Reference: https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html Step-02-01: MAC - Install and configure kubectl Kubectl version we are using here is 1.16.8 (It may vary based on Cluster version you are planning use in AWS EKS) # Download the Package\rmkdir kubectlbinary\rcd kubectlbinary\rcurl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.16.8/2020-04-16/bin/darwin/amd64/kubectl\r# Provide execute permissions\rchmod +x ./kubectl\r# Set the Path by copying to user Home Directory\rmkdir -p $HOME/bin \u0026\u0026 cp ./kubectl $HOME/bin/kubectl \u0026\u0026 export PATH=$PATH:$HOME/bin\recho 'export PATH=$PATH:$HOME/bin' \u003e\u003e ~/.bash_profile\r# Verify the kubectl version\rkubectl version --short --client\rOutput: Client Version: v1.16.8-eks-e16311\rStep-02-02: Windows 10 - Install and configure kubectl Install kubectl on Windows 10 mkdir kubectlbinary\rcd kubectlbinary\rcurl -o kubectl.exe https://amazon-eks.s3.us-west-2.amazonaws.com/1.16.8/2020-04-16/bin/windows/amd64/kubectl.exe\rUpdate the system Path environment variable C:\\Users\\KALYAN\\Documents\\kubectlbinary\rVerify the kubectl client version kubectl version --short --client\rkubectl version --client\rStep-03: Install eksctl CLI Step-03-01: eksctl on Mac # Install Homebrew on MacOs\r/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\r# Install the Weaveworks Homebrew tap.\rbrew tap weaveworks/tap\r# Install the Weaveworks Homebrew tap.\rbrew install weaveworks/tap/eksctl\r# Verify eksctl version\reksctl version\rStep-03-02: eksctl on windows or linux For windows and linux OS, you can refer below documentation link. Reference: https://docs.aws.amazon.com/eks/latest/userguide/eksctl.html#installing-eksctl References: https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html Create EKS Cluster \u0026 Node Groups Step-00: Introduction Understand about EKS Core Objects Control Plane Worker Nodes \u0026 Node Groups Fargate Profiles VPC Create EKS Cluster Associate EKS Cluster to IAM OIDC Provider Create EKS Node Groups Verify Cluster, Node Groups, EC2 Instances, IAM Policies and Node Groups Step-01: Create EKS Cluster using eksctl It will take 15 to 20 minutes to create the Cluster Control Plane # Create Cluster\reksctl create cluster --name=eksdemo1 \\\r--region=us-east-1 \\\r--zones=us-east-1a,us-east-1b \\\r--without-nodegroup # Get List of clusters\reksctl get cluster Step-02: Create \u0026 Associate IAM OIDC Provider for our EKS Cluster To enable and use AWS IAM roles for Kubernetes service accounts on our EKS cluster, we must create \u0026 associate OIDC identity provider. To do so using eksctl we can use the below command. Use latest eksctl version (as on today the latest version is 0.21.0) # Template\reksctl utils associate-iam-oidc-provider \\\r--region region-code \\\r--cluster \u003ccluter-name\u003e \\\r--approve\r# Replace with region \u0026 cluster name\reksctl utils associate-iam-oidc-provider \\\r--region us-east-1 \\\r--cluster eksdemo1 \\\r--approve\rStep-03: Create EC2 Keypair Create a new EC2 Keypair with name as kube-demo This keypair we will use it when creating the EKS NodeGroup. This will help us to login to the EKS Worker Nodes using Terminal. Step-04: Create Node Group with additional Add-Ons in Public Subnets These add-ons will create the respective IAM policies for us automatically within our Node Group role. # Create Public Node Group eksctl create nodegroup --cluster=eksdemo1 \\\r--region=us-east-1 \\\r--name=eksdemo1-ng-public1 \\\r--node-type=t3.medium \\\r--nodes=2 \\\r--nodes-min=2 \\\r--nodes-max=4 \\\r--node-volume-size=20 \\\r--ssh-access \\\r--ssh-public-key=kube-demo \\\r--managed \\\r--asg-access \\\r--external-dns-access \\\r--full-ecr-access \\\r--appmesh-access \\\r--alb-ingress-access Step-05: Verify Cluster \u0026 Nodes Verify NodeGroup subnets to confirm EC2 Instances are in Public Subnet Verify the node group subnet to ensure it created in public subnets Go to Services -\u003e EKS -\u003e eksdemo -\u003e eksdemo1-ng1-public Click on Associated subnet in Details tab Click on Route Table Tab. We should see that internet route via Internet Gateway (0.0.0.0/0 -\u003e igw-xxxxxxxx) Verify Cluster, NodeGroup in EKS Management Console Go to Services -\u003e Elastic Kubernetes Service -\u003e eksdemo1 List Worker Nodes # List EKS clusters\reksctl get cluster\r# List NodeGroups in a cluster\reksctl get nodegroup --cluster=\u003cclusterName\u003e\r# List Nodes in current kubernetes cluster\rkubectl get nodes -o wide\r# Our kubectl context should be automatically changed to new cluster\rkubectl config view --minify\rVerify Worker Node IAM Role and list of Policies Go to Services -\u003e EC2 -\u003e Worker Nodes Click on IAM Role associated to EC2 Worker Nodes Verify Security Group Associated to Worker Nodes Go to Services -\u003e EC2 -\u003e Worker Nodes Click on Security Group associated to EC2 Instance which contains remote in the name. Verify CloudFormation Stacks Verify Control Plane Stack \u0026 Events Verify NodeGroup Stack \u0026 Events Login to Worker Node using Keypai kube-demo Login to worker node # For MAC or Linux or Windows10\rssh -i kube-demo.pem ec2-user@\u003cPublic-IP-of-Worker-Node\u003e\r# For Windows 7\rUse putty\rStep-06: Update Worker Nodes Security Group to allow all traffic We need to allow All Traffic on worker node security group Additional References https://docs.aws.amazon.com/eks/latest/userguide/enable-iam-roles-for-service-accounts.html https://docs.aws.amazon.com/eks/latest/userguide/create-service-account-iam-policy-and-role.html EKS Cluster Pricing Steo-01: Very Important EKS Pricing Note EKS is not free (Unlike other AWS Services) In short, no free-tier for EKS. EKS Cluster Pricing - We pay $0.10 per hour for each Amazon EKS cluster\r- Per Day: $2.4\r- For 30 days: $72\rEKS Worker Nodes Pricing - EC2 - You pay for AWS resources (e.g. EC2 instances or EBS volumes) - T3 Medium Server in N.Virginia\r- $0.0416 per Hour\r- Per Day: $0.9984 - Approximately $1\r- Per Month: $30 per 1 t3.medium server\r- Reference: https://aws.amazon.com/ec2/pricing/on-demand/\r- In short, if we run 1 EKS Cluster and 1 t3.medium worker node **continuously** for 1 month, our bill is going to be around $102 to $110\r- If we take 5 days to complete this course, and if we run 1 EKS Cluster and 2 t3.medium Worker nodes continuosly for 5 days it will cost us approximately around $25. EKS Fargate Profile - AWS Fargate pricing is calculated based on the **vCPU and memory** resources used from the time you start to download your container image until the EKS Pod terminates.\r- **Reference:** https://aws.amazon.com/fargate/pricing/ - Amazon EKS support for AWS Fargate is available in us-east-1, us-east-2, eu-west-1, and ap-northeast-1.\rImportant Notes Important Note-1: If you are using your personal AWS Account, then ensure you delete and recreate cluster and worker nodes as and when needed. Important Note-2: We cant stop our EC2 Instances which are in Kubernetes cluster unlike regular EC2 Instances. So we need to delete the worker nodes (Node Group) if we are not using it during our learning process. Delete EKS Cluster \u0026 Node Groups Step-01: Delete Node Group We can delete a nodegroup separately using below eksctl delete nodegroup # List EKS Clusters\reksctl get clusters\r# Capture Node Group name\reksctl get nodegroup --cluster=\u003cclusterName\u003e\reksctl get nodegroup --cluster=eksdemo1\r# Delete Node Group\reksctl delete nodegroup --cluster=\u003cclusterName\u003e --name=\u003cnodegroupName\u003e\reksctl delete nodegroup --cluster=eksdemo1 --name=eksdemo1-ng-public1\rStep-02: Delete Cluster We can delete cluster using eksctl delete cluster # Delete Cluster\reksctl delete cluster \u003cclusterName\u003e\reksctl delete cluster eksdemo1\rImportant Notes Note-1: Rollback any Security Group Changes When we create a EKS cluster using eksctl it creates the worker node security group with only port 22 access. When we progress through the course, we will be creating many NodePort Services to access and test our applications via browser. During this process, we need to add an additional rule to this automatically created security group, allowing access to our applications we have deployed. So the point we need to understand here is when we are deleting the cluster using eksctl, its core components should be in same state which means roll back the change we have done to security group before deleting the cluster. In this way, cluster will get deleted without any issues, else we might have issues and we need to refer cloudformation events and manually delete few things. In short, we need to go to many places for deletions. Note-2: Rollback any EC2 Worker Node Instance Role - Policy changes When we are doing EBS Storage Section with EBS CSI Driver we will add a custom policy to worker node IAM role. When you are deleting the cluster, first roll back that change and delete it. This way we don’t face any issues during cluster deletion.",
    "tags": [],
    "title": "EKS Installation",
    "uri": "/eks/k8s/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/index.html"
  }
]
